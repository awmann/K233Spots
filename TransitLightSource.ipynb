{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code should do the following:<br>\n",
    "XXX&nbsp;  1) Take an input temperature and spew back a model spectrum<br>\n",
    "&nbsp; 2) Take two spectra and compute relevant flux contribution from each, given a filter profile<br>\n",
    "&nbsp;     3) Compute the adjusted transit depth assuming unocculted spots with the properties above<br>\n",
    "&nbsp;     4) Take a model transmission spectrum, adjust it according to two parameters:<br>\n",
    "&nbsp; &nbsp;         Spot Teff (converted to contrast using 1-3)<br>\n",
    " &nbsp; &nbsp;        Spot coverage<br>\n",
    "&nbsp;     5) Compare that model transmission spectrum to observed data inside emcee. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.timeseries import LombScargle\n",
    "import astropy.units as u\n",
    "import healpy as hp\n",
    "from lightkurve import search_lightcurvefile\n",
    "from emcee import EnsembleSampler\n",
    "from multiprocessing import Pool\n",
    "from corner import corner\n",
    "from astropy.io import fits\n",
    "from ldtk import LDPSetCreator, BoxcarFilter, TabulatedFilter\n",
    "import emcee\n",
    "from multiprocessing import Pool\n",
    "from scipy import stats\n",
    "import numpy.random as random\n",
    "from scipy import optimize\n",
    "import emcee\n",
    "import corner\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "ncpu = cpu_count()\n",
    "print(\"{0} CPUs\".format(ncpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(var):\n",
    "    if type(var) is list:\n",
    "        return str(var)[1:-1] # list\n",
    "    if type(var) is np.ndarray:\n",
    "        try:\n",
    "            return str(list(var[0]))[1:-1] # numpy 1D array\n",
    "        except TypeError:\n",
    "            return str(list(var))[1:-1] # numpy sequence\n",
    "    return str(var) # everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = '/Users/andrewmann/Dropbox/Radii/Models_CIFIST_Aug2013_filler.fits'\n",
    "hdul = fits.open(modelpath)\n",
    "hdul.info()\n",
    "hdr = hdul[1].header\n",
    "data = hdul[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getspec(data, inteff): ##  for now other parameters are fixed\n",
    "\n",
    "    teff = np.squeeze(data['teff'])\n",
    "    logg = np.squeeze(data['logg'])\n",
    "    afe = np.squeeze(data['a_fe'])\n",
    "    mh = np.squeeze(data['metal'])\n",
    "    header = (data['header'])\n",
    "    spectra = np.squeeze(data['spectrum'])\n",
    "    lambda0 = 100\n",
    "    nlambda = 99901\n",
    "    dlambda = 1\n",
    "    wave = np.linspace(lambda0,lambda0+nlambda*dlambda,num=nlambda)\n",
    "    loc = np.where((teff == inteff) & (logg == 4.5) & (afe == 0) & (mh == 0))\n",
    "    if np.size(loc) < 1:\n",
    "        ## interpolate\n",
    "        above = np.min(np.where((logg == 4.5) & (afe == 0) & (mh == 0) & (teff > inteff)))\n",
    "        below = np.max(np.where((logg == 4.5) & (afe == 0) & (mh == 0) & (teff < inteff)))\n",
    "        spec1 = np.squeeze(spectra[:,above])\n",
    "        spec2 = np.squeeze(spectra[:,below])\n",
    "        weight = (inteff-teff[below])/(teff[above]-teff[below])\n",
    "        spec = (1.-weight)*spec1 + weight*spec2\n",
    "    else:\n",
    "        spec = np.squeeze(spectra[:,loc])\n",
    "    #plt.plot(wave,spec)\n",
    "    #plt.yscale('log')\n",
    "    #plt.xscale('log')\n",
    "    #plt.xlim(5000,50000)\n",
    "    #ylimit = [np.min(spec[np.where((wave>5000) & (wave<50000))]),np.max(spec[np.where((wave>5000) & (wave<50000))])]\n",
    "    #plt.ylim(ylimit[0],ylimit[1])\n",
    "    #plt.show()\n",
    "    return(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(data['teff']))\n",
    "lambda0 = 100\n",
    "nlambda = 99901\n",
    "dlambda = 1\n",
    "wave = np.linspace(lambda0,lambda0+nlambda*dlambda,num=nlambda)\n",
    "spec1 = getspec(data,3800)\n",
    "spec2 = getspec(data,3750)\n",
    "spec3 = getspec(data,3700)\n",
    "plt.plot(wave,spec1,label='3800')\n",
    "plt.plot(wave,spec2,label='3750')\n",
    "plt.plot(wave,spec3,label='3700')\n",
    "plt.xlim(3000,30000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "\n",
    "def convolve_filter(w,s,fw,ft):\n",
    "    interpfunc = interpolate.interp1d(w, s, kind='linear')\n",
    "    interpolflux = interpfunc(fw)\n",
    "    flux = np.sum(ft*interpolflux)\n",
    "    return(flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = np.genfromtxt('filters/mearth.tsv', delimiter=';', unpack=True)\n",
    "x*=10\n",
    "plt.plot(x,y, label='MEarth')\n",
    "mearth = TabulatedFilter('mearth', x[np.isfinite(y)], y[np.isfinite(y)])\n",
    "\n",
    "x, y = np.genfromtxt('filters/pstr-zs-avg.txt', unpack=True)\n",
    "x*=10\n",
    "plt.plot(x,y, label='zs')\n",
    "zs = TabulatedFilter('zs', x[np.isfinite(y)], y[np.isfinite(y)])\n",
    "\n",
    "x, y = np.genfromtxt('filters/tess-response-function-v1.0.csv', unpack=True, comments='#', delimiter=',')\n",
    "x*=10\n",
    "plt.plot(x,y, label='tess')\n",
    "tess = TabulatedFilter('tess', x[np.isfinite(y)], y[np.isfinite(y)])\n",
    "\n",
    "x, y = np.genfromtxt('filters/080924ch1trans_full.txt', unpack=True, comments='#', delimiter=',')\n",
    "x*=10000\n",
    "plt.plot(x,y, label='Sp1')\n",
    "s1 = TabulatedFilter('S1', x[np.isfinite(y)], y[np.isfinite(y)])\n",
    "\n",
    "x, y = np.genfromtxt('filters/080924ch2trans_full.txt', unpack=True, comments='#', delimiter=',')\n",
    "x*=10000\n",
    "plt.plot(x,y, label='Sp2')\n",
    "s2 = TabulatedFilter('S2', x[np.isfinite(y)], y[np.isfinite(y)])\n",
    "\n",
    "x,y = np.genfromtxt('filters/Kepler_Kepler.K.dat', unpack=True, comments='#', delimiter=',')\n",
    "#x/=10\n",
    "plt.plot(x,y, label='Kepler')\n",
    "kepler = TabulatedFilter('Kepler', x[np.isfinite(y)], y[np.isfinite(y)])\n",
    "\n",
    "x,y = np.genfromtxt('filters/HST_WFC3_IR.G141.dat', unpack=True, comments='#', delimiter=' ')\n",
    "#x/=10\n",
    "plt.plot(x,y, label='G141')\n",
    "G141 = TabulatedFilter('G141', x[np.isfinite(y)], y[np.isfinite(y)])\n",
    "\n",
    "## HST bands\n",
    "b1 = [11108,11416,11709,11988,12257,12522,12791,13058,13321,13586,13860,14140,14425,14719,15027,15345,15682,16042]\n",
    "b2 = [11416,11709,11988,12257,12522,12791,13058,13321,13586,13860,14140,14425,14719,15027,15345,15682,16042,16432]\n",
    "b1 = [11108,11773.5,12439,13104.5,13770,14435.5,15101,15766.5]\n",
    "b2 = [11773.5,12439,13104.5,13770,14435.5,15101,15766.5,16432]\n",
    "nbins = 8\n",
    "tmp = np.linspace(10880,16800,nbins+1)\n",
    "b1 = np.round(tmp[0:nbins])\n",
    "b2 = np.round(tmp[1:nbins+1])\n",
    "b1_num = np.array(b1)#/10\n",
    "b2_num = np.array(b2)#/10\n",
    "HST_bands = []\n",
    "hst_names = np.array(b1,dtype=str)\n",
    "for i in range(0,np.size(b1)):\n",
    "    str1 = (to_str(round(b1[i])))\n",
    "    str2 = (to_str(round(b2[i])))\n",
    "    hst_names[i] = str(str1)+'--'+str(str2)         \n",
    "counter = 1\n",
    "for i,j in zip(b1_num,b2_num):\n",
    "    HST_bands.append(BoxcarFilter('HST'+str(counter),i,j))\n",
    "    counter=counter+1\n",
    "\n",
    "    \n",
    "#print(HST_bands)\n",
    "filters = HST_bands\n",
    "filters.append(mearth)\n",
    "filters.append(kepler)\n",
    "filters.append(s1)\n",
    "filters.append(s2)\n",
    "print(filters[1].name)\n",
    "fnames = []\n",
    "for i in range(0,np.size(filters)):\n",
    "    fnames = np.append(fnames,filters[i].name)\n",
    "## wl (double-u el) and tm\n",
    "filters[10].__dict__.keys()\n",
    "#filters[0].name\n",
    "#names\n",
    "#print(G141.tm)\n",
    "inc = np.squeeze(np.where(fnames == 'HST1'))\n",
    "print(filters[inc].__dict__.keys())\n",
    "hasattr(filters[inc],'wl_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## given depth (D), spot fraction (fS), and two spectra, compute the adjusted transit depth\n",
    "def depth_adjust(filt,D,fS,wav,surf,spot):\n",
    "    star = surf*(1.-fS) + spot*fS\n",
    "    outoftransit = star\n",
    "    intransit = (surf-surf*(D/(1.-fS)))*(1.-fS) + spot*fS\n",
    "    transit = (outoftransit-intransit)/outoftransit\n",
    "    if hasattr(filt,'wl'):\n",
    "        wl = filt.wl\n",
    "        tm = filt.tm\n",
    "    else:\n",
    "        wl = np.arange(filt.wl_min,filt.wl_max,1)\n",
    "        tm = wl*0+1.\n",
    "    #plt.plot(wav,transit)\n",
    "    #plt.xlim(np.min(wl),np.max(wl))\n",
    "    #plt.ylim(D*0.99,D*1.2)\n",
    "    #plt.show()\n",
    "    outoftransit_flux = convolve_filter(wav,outoftransit,wl,tm)\n",
    "    intransit_flux = convolve_filter(wav,intransit,wl,tm)\n",
    "    #measured = convolve_filter(wav,transit,wl,tm)\n",
    "    #outoftransit_flux = convolve_filter(wav,outoftransit,wl,tm)\n",
    "    #intransit_flux = convolve_filter(wav,intransit,wl,tm)\n",
    "    newD = (outoftransit_flux-intransit_flux)/outoftransit_flux\n",
    "    return(newD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda0 = 100\n",
    "nlambda = 99901\n",
    "dlambda = 1\n",
    "wave = np.linspace(lambda0,lambda0+nlambda*dlambda,num=nlambda)\n",
    "star = getspec(data,3800)\n",
    "spot = getspec(data,3200)\n",
    "\n",
    "fSpot = 0.4\n",
    "Depth = 0.0013\n",
    "print(np.size(filters))\n",
    "model_depths = []\n",
    "for i in range(0,np.size(filters)):\n",
    "    filt = filters[i]\n",
    "    newD = depth_adjust(filt,Depth,fSpot,wave,star,spot)\n",
    "    print(filt.name,newD)\n",
    "    model_depths.append(newD)\n",
    "# inc = np.squeeze(np.where(fnames == 'tess'))\n",
    "# wl = filters[inc].wl\n",
    "# tm = filters[inc].tm\n",
    "# star2 = star*5\n",
    "# t3 = convolve_filter(wave,spot,wl,tm)\n",
    "# t2 = convolve_filter(wave,star,wl,tm)\n",
    "# t1 = convolve_filter(wave,star2,wl,tm)\n",
    "# print(t3,t2,t1)\n",
    "\n",
    "# interpfunc1 = interpolate.interp1d(wave, star, kind='linear')\n",
    "# interpfunc2 = interpolate.interp1d(wave, star2, kind='linear')\n",
    "# match1 = interpfunc1(wl)\n",
    "# match2 = interpfunc2(wl)\n",
    "# plt.plot(wave,star)\n",
    "# plt.plot(wl,match1)\n",
    "# plt.plot(wl,match2)\n",
    "# print(np.sum(tm*match1))\n",
    "# print(np.sum(tm*match2))\n",
    "# plt.xlim(5000,11000)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in some data\n",
    "depth, err = np.loadtxt('bins_result_run46.dat',unpack=True,skiprows=1)\n",
    "\n",
    "print(depth-model_depths,(depth-model_depths)/err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions for MCMC\n",
    "def ln_prior(theta):\n",
    "    fS, Tspot, D = theta\n",
    "    if fS < 0.0 or fS > 1 or Tspot < 2700 or Tspot > 3700 or D < 0 or D > 1:\n",
    "        return -np.inf\n",
    "    return 0\n",
    "\n",
    "def ln_likelihood(theta, depth_obs, depth_err, filters, data, swave):\n",
    "    fS, Tspot, D = theta\n",
    "    star = getspec(data,3470)\n",
    "    spot = getspec(data,Tspot)\n",
    "    \n",
    "    depth_model = []\n",
    "    for filt in filters:\n",
    "        newD = depth_adjust(filt,D,fS,swave,star,spot)\n",
    "        depth_model.append(newD)\n",
    "\n",
    "    s_squared = np.square(depth_err)\n",
    "    p = (1. / np.sqrt(2 * np.pi * s_squared)) * np.exp(-np.square(depth_obs - depth_model) / (2 * s_squared)) \n",
    "    output = np.sum(np.log(p))\n",
    "    return output\n",
    "\n",
    "\n",
    "def ln_posterior(theta, depth_obs, depth_err, filters, data, swave):\n",
    "    ln_p = ln_prior(theta)\n",
    "    if not np.isfinite(ln_p):\n",
    "        return -np.inf\n",
    "    ln_like = ln_likelihood(theta, depth_obs, depth_err, filters, data, swave)\n",
    "    if not np.isfinite(ln_like):\n",
    "        return -np.inf\n",
    "    return ln_p + ln_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import emcee\n",
    "nwalkers, ndim = 16, 3\n",
    "nthreads = 8\n",
    "initial_guesses = [0.4, 3500, 0.0013]\n",
    "print('if this is inf, we have a problem:')\n",
    "print(ln_posterior(initial_guesses,depth,err,filters,data,wave))\n",
    "pos_0 = [initial_guesses*(1+0.01*np.random.randn(ndim)) for i in range(nwalkers)]\n",
    "\n",
    "nsteps = 1000\n",
    "burn = 100\n",
    "thin = 2\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, ln_posterior, args=(depth,err,filters,data,wave), threads=nthreads)\n",
    "sampler.run_mcmc(pos_0, nsteps,progress=True)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_samples = sampler.get_chain(discard=burn, thin=thin, flat=True)\n",
    "labels = ['Spot Frac','Spot Teff','True Depth']\n",
    "import corner\n",
    "print(flat_samples.shape)\n",
    "fig = corner.corner( \n",
    "    flat_samples, labels=labels, show_titles=True,\n",
    "    fill_contours=True, plot_datapoints=False,title_kwargs={\"fontsize\": 11},title_fmt='.4f',\n",
    "    hist_kwargs={\"linewidth\": 2.5},levels=[(1-np.exp(-0.5)),(1-np.exp(-2)),(1-np.exp(-4.5))]\n",
    ");\n",
    "\n",
    "plt.show()#savefig('Corner_'+catalog+'_'+adderr+'_'+str(cut)+'_'+str(minsep)+adder+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
